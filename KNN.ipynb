{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "$\\newcommand{\\ht}{\\hat \\theta} $\n",
    "$\\newcommand{\\vt}{\\vec \\theta} $\n",
    "$\\newcommand{\\ve}{\\vec \\epsilon} $\n",
    "$\\newcommand{\\vx}{\\vec x} $\n",
    "$\\newcommand{\\vy}{\\vec y} $\n",
    "$\\newcommand{\\hess}{H^T \\Sigma^{-1} H}$\n",
    "$\\newcommand{\\ce}{{\\cal E}}$\n",
    "$\\newcommand{\\cl}{{\\cal L}}$\n",
    "$\\newcommand{\\cn}{{\\cal N}}$\n",
    "$\\newcommand{\\LH}{{\\cal L}(\\vx|\\vt)}$\n",
    "$\\newcommand{\\PO}{{P}(\\vt|\\vx)}$\n",
    "$\\newcommand{\\PR}{{P}(\\vt)}$\n",
    "$\\newcommand{\\EV}{{P}(\\vx)}$\n",
    "$\\newcommand{\\eqnp}[1]{\\begin{pmatrix} #1 \\end{pmatrix}}$\n",
    "$\\newcommand{\\eqnb}[1]{\\begin{bmatrix} #1 \\end{bmatrix}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams['figure.figsize'] = [16, 8]\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Ignore Python warnings\n",
    "\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# KNN Methods for Classification, Regression, and Oversampling\n",
    "**Sarah Allam s3747328**\n",
    "\n",
    "This is a tutorial for the KNN applications on tasks of classification, regression, and SMOTE. For the classification and the oversampling tasks, we will illustrate the performance of KNN on the DREAM Challenge.\n",
    "DREAM is a supervised classification problem consisting of 359 total input samples, with only 179 labeled samples, and 186 input features. Therefore, the training set is 179 samples and the test set is 180 samples. The problem is to correctly classify the remaining 180 samples as patients with Acute Myeloid Leukemia (AML) or healthy patients (a binary problem). In addition, the dataset is highly imbalanced, with a majority of the samples pertaining to the healthy class. There are only 20 AML samples in the 180 test set.\n",
    "This is a difficult task and to balance the data of the two classes, we will use SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def plot_data_distribution(data, labels):\n",
    "    '''\n",
    "    Plots the imbalanced binary classes.\n",
    "    :param data: inputs, x\n",
    "    :param labels: categorical class labels for the inputs, y\n",
    "    '''\n",
    "    X_train = data[0:len(labels)]\n",
    "\n",
    "    # plot data distribution\n",
    "    healthy = X_train[labels == 1]\n",
    "    aml = X_train[labels == 2]\n",
    "\n",
    "    plt.bar(['Healthy', 'AML'], [healthy.shape[0], aml.shape[0]])\n",
    "    plt.text(0, healthy.shape[0] + 1, str(healthy.shape[0]), ha='center')\n",
    "    plt.text(1, aml.shape[0] + 1, str(aml.shape[0]), ha='center')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Data Distribution')\n",
    "    plt.show()"
   ],
   "execution_count": 140,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "A histogram is a good data vizualization method in order to check the distribution of the data between classes.\n",
    "We can see that the data for the AML patients has very few samples compared to the data with the majority healthy patients."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def load_data():\n",
    "    # Load data\n",
    "    data =np.genfromtxt(\"data.csv\", delimiter=\",\")\n",
    "    labels = np.genfromtxt(\"labels.csv\", delimiter=\",\")\n",
    "    # data = np.loadtxt('data.csv')\n",
    "    # labels = np.loadtxt('labels.csv')\n",
    "\n",
    "    # print number of features and the number of samples\n",
    "    display(\"Number of features: \", data.shape[1])\n",
    "    display(\"Number of samples: \", data.shape[0])\n",
    "    display(\"Number of labels: \", labels.shape[0])\n",
    "    return data, labels\n",
    "\n",
    "data, labels = load_data()\n",
    "plot_data_distribution(data, labels)"
   ],
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "'Number of features: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "186"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Number of samples: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "359"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'Number of labels: '"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "179"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1600x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, \\\n",
    "    recall_score, f1_score\n",
    "\n",
    "def calculate_metric_clf(y_test, y_):\n",
    "    '''\n",
    "    alculates accuracy, precision, recall, f1-score\n",
    "    :param y_test: true labels of the test set\n",
    "    :param y_: predicted labels of the test set\n",
    "    :return: accuracy, precision, recall, f1-score\n",
    "    '''\n",
    "    accuracy = accuracy_score(y_test, y_)\n",
    "    precision = precision_score(y_test, y_)\n",
    "    recall = recall_score(y_test, y_)\n",
    "    f1 = f1_score(y_test, y_, average='weighted')\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy is not a good metric score for imbalanced datasets. Classification models tend to overfit on the majority class.\n",
    "This also applies to KNN, since the boundary between the two clusters will be defined by mostly healthy samples. Therefore,\n",
    "the KNN model will tend to be biased towards the majority class. For example, in case the model is completely biased towards the majority class and\n",
    "classifies any incoming inputs as the majority class, the accuracy will still be high:\n",
    "\n",
    "\\begin{align}\n",
    "accuracy = 156 * 100 / 179 =87,15\\%\n",
    "\\end{align}\n",
    "\n",
    "Even when all the minority class samples are misclassified, the accuracy is still 87,15\\%.\n",
    "Instead, we should use precision, recall, and f1-score, which together show information about the rate of true positives, true ngatives, false positives, and false negatives :\n",
    "\n",
    "\\begin{align}\n",
    "precision = true\\_positives / (true\\_positives + false\\_positives) \\\\\n",
    "precision = 156 / (156 + 23)=87,15\\%\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "recall = true\\_positives / (true\\_positives + true\\_negatives) \\\\\n",
    "recall = 156 / (156 + 0)=100\\%\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "recall = 2 * precision * recall / (precision + recall) \\\\\n",
    "recall = 93,133\\%\n",
    "\\end{align}\n",
    "\n",
    "The F1-score is a combination between precision and recall. Accuracy does not allow to separate the weight given to the false negatives (AML patients classified as healthy) from false positives (healthy patients classified as AML patients).\n",
    "In the medical domain, it is more grave to miss an AML patient as being healthy, and therefore endangering their life, than treating a healthy patient as a possibly AML patient, which would just result in more tests.\n",
    "Therefore, the metrics used for imbalanced datasets where class predictions are not equally important must be chosen carefully.\n",
    "\n",
    "Next, we will look at a KNN classification on the popular IRIS dataset, where we will only take into consideration 2 features from the dataset in order to plot the KNN boundaries on the predictions.\n",
    "\n",
    "You can interact with the graph by changing the hyperparameters of the KNN model:\n",
    "1. Number of neighbours: this is usually written as 'k' (K-Nearest Neighbours) and decides how many samples will be used to calculate the distance between the input to be classified and the samples in the vicinity. A number that is too small will not generalize well, while a number that is too high will lead to the majority class completely overtaking the minority samples.\n",
    "2. Weight determining neighbours: ‘uniform’ weights all the neighbouring samples equally, while 'distance' weights samples by the inverse of their distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=20, description='Number of neighbours:', max=30, min=1), Dropdown(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69f3a197122f443d95b5e7758bf1c72f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.generate_knn_iris(n_neighbors, knn_weights)>"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Load the IRIS dataset and split the data into a training set and a test set\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"sepal length (cm)\", \"sepal width (cm)\"]]\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "\n",
    "# Function to generate and plot points\n",
    "def generate_knn_iris(n_neighbors, knn_weights):\n",
    "    '''\n",
    "    KNN classifier applied on the IRIS dataset. Plots the 2 features of the data and the KNN boundaries\n",
    "    :param n_neighbors: k\n",
    "    :param knn_weights: uniform or distance\n",
    "    :return: plot\n",
    "    '''\n",
    "    np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "    clf = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=n_neighbors, weights=knn_weights))]\n",
    "    )\n",
    "    _, axs = plt.subplots(ncols=1, figsize=(12, 5))\n",
    "\n",
    "    clf.set_params(knn__weights=knn_weights).fit(X_train, y_train)\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        X_test,\n",
    "        response_method=\"predict\",\n",
    "        plot_method=\"pcolormesh\",\n",
    "        xlabel=iris.feature_names[0],\n",
    "        ylabel=iris.feature_names[1],\n",
    "        shading=\"auto\",\n",
    "        alpha=0.5,\n",
    "        ax=axs,\n",
    "    )\n",
    "    scatter = disp.ax_.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, edgecolors=\"k\")\n",
    "    disp.ax_.legend(\n",
    "        scatter.legend_elements()[0],\n",
    "        iris.target_names,\n",
    "        loc=\"lower left\",\n",
    "        title=\"Classes\",\n",
    "    )\n",
    "    _ = disp.ax_.set_title(\n",
    "        f\"3-Class classification\\n(k={clf[-1].n_neighbors}, weights={knn_weights!r})\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "# Interactive sliders for the number and variance of points\n",
    "interact(\n",
    "    generate_knn_iris,\n",
    "    n_neighbors=widgets.IntSlider(min=1, max=30, step=1, value=20, description='Number of neighbours:'),\n",
    "    knn_weights = widgets.Dropdown(\n",
    "    options=[(\"uniform\", \"uniform\"), (\"distance\", \"distance\")],\n",
    "    value=\"uniform\",\n",
    "    description='Weight determining neighbours:',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We return to our DREAM challenge, on the AML dataset. Since there are more than 2 features, we cannot plot all of the feature space against the boundaries, but we can plot the binary class probabilities against two selected features and observe the false negatives/positives rates and the importance of the features for the classification.\n",
    "After we fit the KNN model on the training set, we plot the probability of each class for the test set samples. The classes are one-hot encoded: it transforms categorical data into integers. The first class, class '1', is the 'healthy' class. The second class, class '2', is the 'AML' minority class.\n",
    "You can hover over each data point in order to observe the probability of either class and the true label.\n",
    "There are very few samples in the minority class compared to the majority one, and their class probabilities are spread out. In comparison, the majority class samples tend to have a lower variance within the feature space.\n",
    "Change the two features and see how the probabilities for the classification change alongside the spread of the samples in the feature space."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = data[:179]\n",
    "y = labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "\n",
    "# Function to generate and plot points\n",
    "def generate_knn_clf(n_neighbors, knn_weights,feature_1, feature_2):\n",
    "    '''\n",
    "    KNN Classification for the AML dataset. Plots 2 features and the class probabilities.\n",
    "    :param n_neighbors: k\n",
    "    :param knn_weights: uniform or distance\n",
    "    :param feature_1: index of the x-axis feature\n",
    "    :param feature_2: index of the y-axis feature\n",
    "    :return:\n",
    "    '''\n",
    "    np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors, weights=knn_weights)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    # this one gives a categorical prediction instead of a probability\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    fig = px.scatter(\n",
    "        X_test, x=feature_1, y=feature_2,\n",
    "        color=y_score, color_continuous_scale='RdBu',\n",
    "        symbol=np.squeeze(y_test),\n",
    "        symbol_map={'1': 'square-dot', '2': 'circle-dot'},\n",
    "        labels={'symbol': 'label', 'color': 'score of <br>first class'}\n",
    "    )\n",
    "    fig.update_traces(marker_size=12, marker_line_width=1.5)\n",
    "    fig.update_layout(legend_orientation='h')\n",
    "    fig.show()\n",
    "\n",
    "# Interactive sliders for the number and variance of points\n",
    "interact(\n",
    "    generate_knn_clf,\n",
    "    n_neighbors=widgets.IntSlider(min=1, max=50, step=1, value=11, description='Number of neighbours:'),\n",
    "    knn_weights = widgets.Dropdown(\n",
    "    options=[(\"uniform\", \"uniform\"), (\"distance\", \"distance\")],\n",
    "    value=\"uniform\",\n",
    "    description='Weight determining neighbours:',\n",
    "    ),\n",
    "    feature_1=widgets.IntSlider(min=0, max=185, step=1, value=0, description='Index of Feature 1:'),\n",
    "    feature_2=widgets.IntSlider(min=0, max=185, step=1, value=1, description='Index of Feature 2:'),\n",
    "\n",
    ")"
   ],
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=11, description='Number of neighbours:', max=50, min=1), Dropdown(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b7e23fc935b473f99f174c8ef216bd9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.generate_knn_clf(n_neighbors, knn_weights, feature_1, feature_2)>"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can apply Principal Component Analysis (PCA) in order to select the best 2 features for plotting the class probabilities.\n",
    "However, for non-illustrative purposes, we would apply PCA and then keep enough features in order to explain at least 95% of the variance in the data.\n",
    "When applying PCA, it is important to avoid data leakage. Data leakage happens when information from the training test skews the test set, and therefore the test set becomes biased and is not representative of a generalized performance of the model anymore.\n",
    "Data leakage happens when we apply a dimensionality reduction method like PCA on the whole dataset, before splitting into training and test sets.\n",
    "PCA should be applied separately on the training set and on the test set. If the training set is representative of the test set, the same features should be selected as the principal components for both sets, but that might not always be the case!\n",
    "Below we plot the first and second best features as extracted by PCA and plo the boundaries of the two classes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "def pca(X_train, X_test, n_comps=2):\n",
    "    '''\n",
    "    Standardize data (subtract mean) and apply PCA on the test and training sets separately.\n",
    "    :param X_train: training samples\n",
    "    :param X_test: test samples\n",
    "    :param n_comps: 2, for plotting\n",
    "    :return: transformed train and test samples with only 2 best features\n",
    "    '''\n",
    "    # PCA (on all components)\n",
    "    # standardize data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    pca = PCA(n_components=n_comps)\n",
    "    X_train = pd.DataFrame(pca.fit_transform(X_train))\n",
    "    X_test = pd.DataFrame(pca.transform(X_test))\n",
    "    explained_variance = np.round(pca.explained_variance_ratio_, decimals=3) * 100\n",
    "    display(\"Explained Variance by the first 2 features: \", explained_variance[0] + explained_variance[1])\n",
    "    display(\"Explained Variance: \", pca.explained_variance_ratio_)\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def generate_knn_clf_feature_reduction(n_neighbors, knn_weights):\n",
    "    '''\n",
    "    KNN classification on AML with PCA\n",
    "    :param n_neighbors: k\n",
    "    :param knn_weights: uniform or distance\n",
    "    :return: plots\n",
    "    '''\n",
    "    np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "    # dimensionality reduction with PCA\n",
    "    X_train_pca, X_test_pca = pca(X_train, X_test)\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors, weights=knn_weights)\n",
    "    _, axs = plt.subplots(ncols=1, figsize=(12, 5))\n",
    "    display(\"Training set after PCA\" , X_train_pca)\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        X_test_pca,\n",
    "        response_method=\"predict\",\n",
    "        plot_method=\"pcolormesh\",\n",
    "        xlabel=\"best feature pca\",\n",
    "        ylabel=\"second best feature pca\",\n",
    "        shading=\"auto\",\n",
    "        alpha=0.5,\n",
    "        ax=axs,\n",
    "    )\n",
    "    scatter = disp.ax_.scatter(X_test_pca.iloc[:, 0], X_test_pca.iloc[:, 1], c=y_test, edgecolors=\"k\")\n",
    "    disp.ax_.legend(\n",
    "        scatter.legend_elements()[0],\n",
    "        np.unique(y_test),\n",
    "        loc=\"lower left\",\n",
    "        title=\"Classes\",\n",
    "    )\n",
    "    _ = disp.ax_.set_title(\n",
    "        f\"2-Class classification\\n(k={clf.n_neighbors}, weights={knn_weights!r})\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "    generate_knn_clf_feature_reduction,\n",
    "    n_neighbors=widgets.IntSlider(min=1, max=50, step=1, value=11, description='Number of neighbours:'),\n",
    "    knn_weights = widgets.Dropdown(\n",
    "    options=[(\"uniform\", \"uniform\"), (\"distance\", \"distance\")],\n",
    "    value=\"uniform\",\n",
    "    description='Weight determining neighbours:',\n",
    "    )\n",
    "    # num_blue=widgets.IntSlider(min=1, max=200, step=1, value=100, description='Num Blue Points:'),\n",
    "    # variance_red=widgets.FloatSlider(min=0.1, max=5.0, step=0.1, value=0.5, description='Var Red Points:'),\n",
    "    # variance_blue=widgets.FloatSlider(min=0.1, max=5.0, step=0.1, value=3.0, description='Var Blue Points:')\n",
    ")"
   ],
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=11, description='Number of neighbours:', max=50, min=1), Dropdown(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f143b68eff14087a6970b802f2da7b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.generate_knn_clf_feature_reduction(n_neighbors, knn_weights)>"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "def construct_oversampling(sampling_method, smote_sampling_strategy, X_train_pca, y_train):\n",
    "    if sampling_method == 'SMOTE':\n",
    "        sampler = SMOTE(sampling_strategy=smote_sampling_strategy)\n",
    "        X_samples, y_samples = sampler.fit_resample(X_train_pca, y_train)\n",
    "        return X_samples, y_samples\n",
    "    if sampling_method == 'BorderlineSMOTE':\n",
    "        sampler = BorderlineSMOTE( sampling_strategy=smote_sampling_strategy)\n",
    "        X_samples, y_samples = sampler.fit_resample(X_train_pca, y_train)\n",
    "        return X_samples, y_samples\n",
    "    if sampling_method == 'ADASYN':\n",
    "        sampler = ADASYN( sampling_strategy=smote_sampling_strategy)\n",
    "        X_samples, y_samples = sampler.fit_resample(X_train_pca, y_train)\n",
    "        return X_samples, y_samples\n",
    "    if sampling_method == 'None':\n",
    "        return X_train_pca, y_train\n",
    "\n",
    "\n",
    "def construct_undersampling(sampling_method, smote_sampling_strategy, X_train_pca, y_train):\n",
    "    if sampling_method == 'RandomUnderSampler':\n",
    "        sampler = RandomUnderSampler( sampling_strategy=smote_sampling_strategy)\n",
    "        X_samples, y_samples = sampler.fit_resample(X_train_pca, y_train)\n",
    "        return X_samples, y_samples\n",
    "    if sampling_method == 'None':\n",
    "        return X_train_pca, y_train\n",
    "\n",
    "def generate_knn_clf_smote(n_neighbors, knn_weights, oversampling_method, undersampling_method, smote_oversampling_strategy, smote_undersampling_strategy):\n",
    "    np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "    # dimensionality reduction with PCA\n",
    "    X_train_pca, X_test_pca = pca(X_train, X_test)\n",
    "    X_smote, y_smote = construct_undersampling(undersampling_method, smote_undersampling_strategy, X_train_pca, y_train)\n",
    "    X_smote, y_smote = construct_oversampling(oversampling_method, smote_oversampling_strategy, X_smote, y_smote)\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors, weights=knn_weights)\n",
    "    _, axs = plt.subplots(ncols=1, figsize=(12, 5))\n",
    "    clf.fit(X_smote, y_smote)\n",
    "\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        X_smote,\n",
    "        response_method=\"predict\",\n",
    "        plot_method=\"pcolormesh\",\n",
    "        xlabel=\"best feature pca\",\n",
    "        ylabel=\"second best feature pca\",\n",
    "        shading=\"auto\",\n",
    "        alpha=0.5,\n",
    "        ax=axs,\n",
    "    )\n",
    "    scatter = disp.ax_.scatter(X_smote.iloc[:, 0], X_smote.iloc[:, 1], c=y_smote, edgecolors=\"k\")\n",
    "    disp.ax_.legend(\n",
    "        scatter.legend_elements()[0],\n",
    "        np.unique(y_smote),\n",
    "        loc=\"lower left\",\n",
    "        title=\"Classes\",\n",
    "    )\n",
    "    _ = disp.ax_.set_title(\n",
    "        f\"2-Class classification\\n(k={clf.n_neighbors}, weights={knn_weights!r})\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    y_score = clf.predict_proba(X_smote)[:, 1]\n",
    "    fig = px.scatter(\n",
    "        X_smote, x=0, y=1,\n",
    "        color=y_score, color_continuous_scale='RdBu',\n",
    "        symbol=np.squeeze(y_smote),\n",
    "        symbol_map={'0': 'square-dot', '1': 'circle-dot'},\n",
    "        labels={'symbol': 'label', 'color': 'score of <br>first class'}\n",
    "    )\n",
    "    fig.update_traces(marker_size=12, marker_line_width=1.5)\n",
    "    fig.update_layout(legend_orientation='h')\n",
    "    fig.show()\n",
    "\n",
    "    y_ = clf.predict(X_test_pca)\n",
    "    accuracy, precision, recall, f1 = calculate_metric_clf(y_test, y_)\n",
    "    display(\"Accuracy: \", accuracy)\n",
    "    display(\"precision: \", precision)\n",
    "    display(\"recall: \", recall)\n",
    "    display(\"f1 score: \", f1)\n",
    "\n",
    "\n",
    "interact(\n",
    "    generate_knn_clf_smote,\n",
    "    smote_oversampling_strategy = widgets.Dropdown(\n",
    "    options=[(\"resample only the minority class\", \"minority\"), (\"resample all classes but the minority class\", \"not minority\"),\n",
    "             (\"resample all classes but the majority class\", \"not majority\"), (\"resample all classes\", \"all\")],\n",
    "    value=\"minority\",\n",
    "    description='SMOTE Sampling Strategy:',\n",
    "    ),\n",
    "    smote_undersampling_strategy = widgets.Dropdown(\n",
    "    options=[(\" resample only the majority class\", \"majority\"), (\"resample all classes but the minority class\", \"not minority\"),\n",
    "             (\"resample all classes but the majority class\", \"not majority\"), (\"resample all classes\", \"all\")],\n",
    "    value=\"majority\",\n",
    "    description='SMOTE Sampling Strategy:',\n",
    "    ),\n",
    "    oversampling_method =widgets.Dropdown(\n",
    "    options=[(\"None\", \"None\"), (\"SMOTE\", \"SMOTE\"), (\"BorderlineSMOTE\", \"BorderlineSMOTE\")],\n",
    "    value=\"SMOTE\",\n",
    "    description='Oversampling Method:',\n",
    "    ),\n",
    "    undersampling_method =widgets.Dropdown(\n",
    "    options=[(\"None\", \"None\"), (\"RandomUnderSampler\", \"RandomUnderSampler\")],\n",
    "    value=\"RandomUnderSampler\",\n",
    "    description='Undersampling Method:',\n",
    "    ),\n",
    "    n_neighbors=widgets.IntSlider(min=1, max=50, step=1, value=11, description='Number of neighbours:'),\n",
    "    knn_weights = widgets.Dropdown(\n",
    "    options=[(\"uniform\", \"uniform\"), (\"distance\", \"distance\")],\n",
    "    value=\"uniform\",\n",
    "    description='Weight determining neighbours:',\n",
    "    )\n",
    "    # num_blue=widgets.IntSlider(min=1, max=200, step=1, value=100, description='Num Blue Points:'),\n",
    "    # variance_red=widgets.FloatSlider(min=0.1, max=5.0, step=0.1, value=0.5, description='Var Red Points:'),\n",
    "    # variance_blue=widgets.FloatSlider(min=0.1, max=5.0, step=0.1, value=3.0, description='Var Blue Points:')\n",
    ")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=11, description='Number of neighbours:', max=50, min=1), Dropdown(descri…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef12fce509b34a7f86e37e52492b9549"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.generate_knn_clf_smote(n_neighbors, knn_weights, oversampling_method, undersampling_method, smote_oversampling_strategy, smote_undersampling_strategy)>"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=40, description='Number of data Points:', max=200, min=10), FloatSlider(…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7baaf24b44b9403581cde6e7acf3eb23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<function __main__.generate_knn_regressor(n_data_points, noise, n_neighbors, knn_weights)>"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Function to generate and plot points\n",
    "def generate_knn_regressor(n_data_points, noise, n_neighbors, knn_weights):\n",
    "    np.random.seed(42)\n",
    "    X = np.sort(np.random.rand(n_data_points, 1), axis=0)\n",
    "    T = np.linspace(0, 1, 500)[:, np.newaxis]\n",
    "    y_true = np.sin(X).ravel() # select everything but the last 100 points\n",
    "    y_test = np.sin(T).ravel() # select the last 100 points for test set\n",
    "    # Add noise to targets\n",
    "    # display(noise)\n",
    "    # random_indices = np.random.choice(len(y), size=noise, replace=False)\n",
    "    noise = np.random.normal(loc=0, scale=noise, size=len(y_true))\n",
    "\n",
    "    # Add noise to the original array\n",
    "    y = y_true + noise\n",
    "\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors, weights=knn_weights)\n",
    "    y_ = knn.fit(X, y).predict(T)\n",
    "\n",
    "    error = np.sqrt(mean_squared_error(y_test, y_))\n",
    "    display(\"Error is:  \", error)\n",
    "\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.scatter(X, y, color=\"darkorange\", label=\"noisy data\")\n",
    "    plt.plot(T, y_, color=\"navy\", label=\"prediction\")\n",
    "    plt.plot(X, y_true, color=\"black\", label=\"true function\")\n",
    "    plt.axis(\"tight\")\n",
    "    plt.legend()\n",
    "    plt.title(\"KNeighborsRegressor (k = %i, weights = '%s')\" % (n_neighbors, knn_weights))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive sliders for the number and variance of points\n",
    "interact(\n",
    "    generate_knn_regressor,\n",
    "    n_data_points=widgets.IntSlider(min=10, max=200, step=1, value=40, description='Number of data Points:'),\n",
    "    noise=widgets.FloatSlider(min=0, max=2, step=0.1, value=0.1, description='Noise added to data:'),\n",
    "    n_neighbors=widgets.IntSlider(min=1, max=50, step=1, value=11, description='Number of neighbours:'),\n",
    "    knn_weights = widgets.Dropdown(\n",
    "    options=[(\"uniform\", \"uniform\"), (\"distance\", \"distance\")],\n",
    "    value=\"uniform\",\n",
    "    description='Weight determining neighbours:',\n",
    "    )\n",
    "    # variance_blue=widgets.FloatSlider(min=0.1, max=5.0, step=0.1, value=3.0, description='Var Blue Points:')\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": "3",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "224px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}